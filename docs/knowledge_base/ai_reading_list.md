# Essential AI Reading List

## What this is
A curated list of high-signal sources for staying current on AI, LLMs, agents, and tooling.

## Blogs & Personal Sites
- **Simon Willison** ([simonwillison.net](https://simonwillison.net)) — LLM tooling, prompt engineering, practical AI.
  *Why: Exceptional at documenting the fast-moving practical side of LLMs and open-source tooling.*
- **Lilian Weng** ([lilianweng.github.io](https://lilianweng.github.io/posts/)) — Deep technical surveys of ML topics.
  *Why: Provides some of the most thorough and well-cited technical deep dives on AI architectures and methods.*
- **Jay Alammar** ([jalammar.github.io](https://jalammar.github.io)) — Visual explanations of transformers and LLMs.
  *Why: Master of visual intuition for complex transformer architectures and model mechanics.*
- **Sebastian Raschka** ([sebastianraschka.com](https://sebastianraschka.com)) — LLM training, fine-tuning, evaluation.
  *Why: Bridges research and code with highly reproducible tutorials on training and fine-tuning models.*
- **Chip Huyen** ([huyenchip.com](https://huyenchip.com)) — MLOps, LLM systems design.
  *Why: Leading voice on the infrastructure and systems engineering required to put AI into production.*
- **Eugene Yan** ([eugeneyan.com](https://eugeneyan.com)) — Applied ML, RecSys, LLM patterns.
  *Why: Focused on the practical patterns and "how-to" of building reliable AI-powered products.*
- **Andrej Karpathy** ([karpathy.ai](https://karpathy.ai)) — AI education and deep learning fundamentals.
  *Why: Offers world-class clarity on how LLMs work from first principles and the "LLM OS" concept.*
- **Vicki Boykis** ([vickiboykis.com](https://vickiboykis.com)) — ML engineering and data systems.
  *Why: Provides a grounded, skeptical, and deeply experienced perspective on ML in the real world.*
- **Hamel Husain** ([hamel.dev](https://hamel.dev)) — LLM evaluation and engineering workflows.
  *Why: Expert on the rigors of LLM evaluation and building high-quality AI features.*
- **Jeremy Howard** ([fast.ai](https://www.fast.ai)) — AI education and top-down learning.
  *Why: Pioneer of making deep learning accessible to software engineers through a code-first approach.*
- **François Chollet** ([fchollet.com](https://fchollet.com)) — AI research and intelligence theory.
  *Why: Deep thinker on the nature of intelligence, abstraction, and the limits of current LLM architectures.*

## Newsletters
- **The Batch** (deeplearning.ai) — Andrew Ng's weekly AI digest.
  *Why: High-level synthesis of AI trends and their societal/business impacts from an industry legend.*
- **AI News** ([buttondown.com/ainews](https://buttondown.com/ainews)) — Daily aggregator.
  *Why: Comprehensive daily summary of everything happening in the AI Twitter/X and GitHub ecosystem.*
- **Latent Space** ([latent.space](https://www.latent.space)) — Deep-dive podcast + newsletter.
  *Why: Excellent for understanding the "AI Engineer" stack and emerging implementation patterns.*
- **Import AI** ([jack-clark.net](https://jack-clark.net)) — Jack Clark's curated roundup.
  *Why: Best-in-class coverage of AI policy, safety, and global research milestones.*
- **The Gradient** ([thegradient.pub](https://thegradient.pub)) — Long-form AI analysis.
  *Why: Provides thoughtful, long-form perspectives and debates on the direction of AI research.*
- **TLDR AI** ([tldr.tech/ai](https://tldr.tech/ai)) — Daily technical summary.
  *Why: Quick, skimmable daily digest of the most important AI tools, papers, and news.*
- **Ben's Bites** ([bensbites.co](https://www.bensbites.co)) — Daily AI product updates.
  *Why: Focuses on the "new and shiny" AI products and creative use cases appearing every day.*
- **Interconnects** ([interconnects.ai](https://www.interconnects.ai)) — Frontier model analysis.
  *Why: Deep, practitioner-level analysis of the newest frontier models and research.*
- **AlphaSignal** ([alphasignal.ai](https://alphasignal.ai)) — Technical AI news.
  *Why: Highly technical, signal-heavy newsletter focusing on the latest breakthroughs and code repositories.*

## Research Labs to Follow
- **OpenAI Research** — The industry leader in frontier models and safety-aligned AGI research.
  *Why: Setting the pace for state-of-the-art model capabilities and safety evaluations.*
- **Anthropic Research** — Pioneers of constitutional AI and mechanistic interpretability.
  *Why: Leading research into how models think and how to align them through structural constraints.*
- **Google DeepMind** — Historical powerhouse of fundamental AI breakthroughs and scientific applications.
  *Why: Continues to produce foundational research spanning from LLMs to AI for science.*
- **Meta FAIR** — Leading the charge in high-quality open-source models and fundamental research.
  *Why: Crucial source for open-weights models and research that democratizes AI access.*
- **Mistral** — Proving that small, efficient models can rival giants in performance.
  *Why: Essential for tracking the efficiency frontier and high-performance local inference.*
- **Allen AI (AI2)** — Non-profit research focusing on AI for the common good and open science.
  *Why: Important for open-dataset initiatives and research unbiased by commercial interests.*

## Aggregators & Communities
- **Hacker News (AI filter)** — Real-time discussion and discovery of new AI tools by the engineering community.
  *Why: The best place to find early-stage tools and technical debates among practitioners.*
- **r/LocalLLaMA** — The primary hub for the open-weights and local inference community.
  *Why: Unrivaled for practical tips on running, quantizing, and fine-tuning models locally.*
- **r/MachineLearning** — Serious academic and professional discussion on ML research and engineering.
  *Why: High-density source for paper discussions and professional ML engineering advice.*
- **Papers With Code** — Essential for finding the implementation behind the latest research papers.
  *Why: Bridges the gap between academic theory and practical, runnable implementations.*
- **Hugging Face Daily Papers** — Curated daily feed of the most impactful research papers in the community.
  *Why: Excellent for staying on top of the sheer volume of new research appearing daily.*

## Podcasts
- **Latent Space Podcast** — Deep technical conversations with the builders of the AI engineering era.
  *Why: The best source for understanding the actual engineering trade-offs made by leading practitioners.*
- **Gradient Dissent (W&B)** — Interviews with top ML practitioners about their real-world workflows and challenges.
  *Why: Provides deep insight into the production realities of training and deploying models.*
- **Practical AI** — Accessible discussions on making AI useful in real-world software development.
  *Why: Great for seeing how AI fits into broader software engineering and business contexts.*

## Sources / References
- [Simon Willison's Weblog](https://simonwillison.net/)
- [Lil'Log](https://lilianweng.github.io/posts/)
- [Jay Alammar's Blog](https://jalammar.github.io/)
- [Sebastian Raschka's Blog](https://sebastianraschka.com/)
- [Chip Huyen's Blog](https://huyenchip.com/)
- [Eugene Yan's Blog](https://eugeneyan.com/)
- [Andrej Karpathy's Website](https://karpathy.ai/)
- [Vicki Boykis's Blog](https://vickiboykis.com/)
- [Hamel Husain's Blog](https://hamel.dev/)
- [Fast.ai](https://www.fast.ai/)
- [François Chollet's Website](https://fchollet.com/)
- [The Batch](https://www.deeplearning.ai/the-batch/)
- [AI News](https://buttondown.com/ainews)
- [Latent Space](https://www.latent.space/)
- [Import AI](https://jack-clark.net/)
- [The Gradient](https://thegradient.pub/)
- [TLDR AI](https://tldr.tech/ai)
- [Ben's Bites](https://www.bensbites.co/)
- [Interconnects](https://www.interconnects.ai/)
- [AlphaSignal](https://alphasignal.ai/)

## Contribution Metadata
- Last reviewed: 2026-02-27
- Confidence: high
